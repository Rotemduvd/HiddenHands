export const cases = [
    {
        id: 1,
        teaser: "A government algorithmic system falsely accused over 400,000 welfare recipients of under-reporting income, leading to illegal debt recovery notices.",
        correctCountry: "Australia",
        details: "The 'Robodebt' scheme used an automated data-matching algorithm to average income over a year, incorrectly calculating fortnightly earnings. It shifted the burden of proof to recipients, causing immense financial distress and was eventually ruled unlawful.",
        year: "2016-2019",
        sourceUrl: "https://en.wikipedia.org/wiki/Robodebt_scheme"
    },
    {
        id: 2,
        teaser: "An automated risk profiling system used to detect social security fraud was struck down by courts for violating privacy and human rights (SyRI).",
        correctCountry: "Netherlands",
        details: "The System Risk Indication (SyRI) aggregated data from various government agencies to profile citizens in low-income neighborhoods. A court ruled it violated Article 8 of the ECHR due to lack of transparency and privacy intrusion.",
        year: "2020",
        sourceUrl: "https://www.bbc.com/news/technology-51394933"
    },
    {
        id: 3,
        teaser: "Police forces used a predictive policing algorithm called PredPol to dispatch officers to areas predicted to have high crime rates, reinforcing racial bias.",
        correctCountry: "United States",
        details: "PredPol (now Geolitica) used historical crime data to predict future crimes. Critics and studies showed it created a feedback loop, sending police repeatedly to minority neighborhoods based on biased historical arrest data.",
        year: "2012-Present",
        sourceUrl: "https://www.vice.com/en/article/predictive-policing-predpol-bias/"
    },
    {
        id: 4,
        teaser: "A political consulting firm harvested personal data from millions of Facebook profiles without consent to influence a major election.",
        correctCountry: "United Kingdom",
        details: "Cambridge Analytica obtained data from up to 87 million Facebook users. This data was used to build psychological profiles and target voters with personalized political ads during the Brexit referendum and 2016 US election.",
        year: "2018",
        sourceUrl: "https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal"
    },
    {
        id: 5,
        teaser: "A private company scraped billions of images from social media to build a facial recognition database used by law enforcement agencies.",
        correctCountry: "United States",
        details: "Clearview AI scraped over 3 billion photos from platforms like Facebook and Instagram. It sold its facial recognition tool to police forces, allowing them to identify individuals without a warrant, sparking major privacy lawsuits.",
        year: "2020",
        sourceUrl: "https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html"
    },
    {
        id: 6,
        teaser: "A spy agency used a tool called 'XKeyscore' to search and analyze vast amounts of global internet data, including emails and browsing history.",
        correctCountry: "United States",
        details: "Revealed by Edward Snowden, XKeyscore was used by the NSA to search through vast databases of internet traffic. It allowed analysts to query activities of individuals worldwide without prior authorization.",
        year: "2013",
        sourceUrl: "https://en.wikipedia.org/wiki/XKeyscore"
    },
    {
        id: 7,
        teaser: "An unemployment agencyâ€™s automated system (MiDAS) wrongly accused over 40,000 people of fraud, levying massive fines.",
        correctCountry: "United States",
        details: "The Michigan Integrated Data Automated System (MiDAS) flagged discrepancy in income as fraud with 93% error rate. It automatically seized tax refunds and garnished wages, bankrupting many innocent claimants.",
        year: "2013-2015",
        sourceUrl: "https://www.theguardian.com/technology/2019/dec/11/robot-debt-collectors-credit-card-debt"
    },
    {
        id: 8,
        teaser: "A controversial 'spyware' developed by a private firm was used by governments to infiltrate phones of journalists and activists.",
        correctCountry: "Israel",
        details: "Pegasus, developed by NSO Group, is a zero-click spyware that gives attackers full access to a phone. While intended for criminals, investigations revealed its use by democratic and authoritarian governments alike to spy on civil society.",
        year: "2021",
        sourceUrl: "https://forbiddenstories.org/about-the-pegasus-project/"
    },
    {
        id: 9,
        teaser: "An algorithm used to grade A-Level exams during a pandemic downgraded nearly 40% of student grades, disproportionately affecting improper schools.",
        correctCountry: "United Kingdom",
        details: "Ofqual's algorithm replaced cancelled exams with calculated grades. It heavily weighted the school's historical performance, unfairly downgrading bright students in historically lower-performing schools, leading to public outrage.",
        year: "2020",
        sourceUrl: "https://www.bbc.com/news/education-53804740"
    },
    {
        id: 10,
        teaser: "A proposal for 'Smart Borders' tested an AI lie-detector kiosk to screen travelers before they enter the country.",
        correctCountry: "European Union",
        details: "The iBorderCtrl project piloted an AI system that analyzed micro-expressions to detect lying. Critics argued it was pseudoscience and would lead to discrimination and false rejections at borders.",
        year: "2018",
        sourceUrl: "https://gizmodo.com/the-eu-is-funding-essentially-worthless-ai-lie-detector-1830157618"
    }
];
